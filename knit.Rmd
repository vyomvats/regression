

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Question 2

Reading the data first and saving the week category and scores

```{r, echo=TRUE, message=FALSE, warning=FALSE}
data = read.table("MS Analytics/6414/R Lecture Notes/Simple Linear Regression/depression.txt",header=TRUE)
scores = data[,1]
week = data[,2]
```

**Part 1**

Estimate of the mean depression score two weeks before the earthquake,
Parameter: week = -2

```{r, echo=TRUE, message=FALSE, warning=FALSE}
scores.before = scores[week==-2]
mean(scores.before)
```

Estimate of the mean depression score one week after the earthquake,
Parameter: week = 1

```{r, echo=TRUE, message=FALSE, warning=FALSE}
scores.after.1 = scores[week==1]
mean(scores.after.1)
```

Estimate of the mean depression score four weeks after the earthquake,
Parameter: week = 4

```{r, echo=TRUE, message=FALSE, warning=FALSE}
scores.after.4 = scores[week==4]
mean(scores.after.4)
```

Estimate of the mean depression score seven weeks after the earthquake,
Parameter: week = 7

```{r, echo=TRUE, message=FALSE, warning=FALSE}
scores.after.7 = scores[week==7]
mean(scores.after.7)
```

Estimate of the mean depression score ten weeks after the earthquake,
Parameter: week = 10

```{r, echo=TRUE, message=FALSE, warning=FALSE}
scores.after.10 = scores[week==10]
mean(scores.after.10)
```


**Part 2**

Conducting exploratory data analysis by drawing box plots

```{r, echo=TRUE, message=FALSE, warning=FALSE}
boxplot(scores ~ as.factor(week), xlab = "Week", ylab = "Depression score")
title(main = "Boxplots of all five weeks")
```

Looking at the mean values, it can be seen that the mean depression scores across different weeks do not differ by a large value, although all the mean scores after the earthquake are higher than the mean score before the earthquake. Also, the largest variance in depression scores occurs in the 7th week after the earthquake and the smallest variance occurs in the 4th week after the earthquake.

**Part 3**

ANOVA of the depression scores

```{r, echo=TRUE, message=FALSE, warning=FALSE}
# converting week to factor type before running ANOVA
week = as.factor(week)

# preparing the ANOVA model and fetching summary
anova_model = aov(scores ~ week)
summary(anova_model)
```

**Part 3(a)**

The appropriate $H_{0}$ and $H_{1}$ are:

- $H_{0}$ : Mean depression scores across all weeks are equal to each other, i.e.,

$\mu_{1} = \mu_{2} = \mu_{3} = \mu_{4} = \mu_{5}$

- $H_{1}$ : Mean depression scores across all weeks are not same (Atleast one mean score is different from the rest)

**Part 3(b)**

The F test statistic (as observed from the R output) is: **2.383**

**Part 3(c)**

The p-value of the ANOVA test (as observed from the R output) is: **0.0552**. At a **95%** confidence level, this value lies on the borderline of rejection/failure of rejection. Strictly speaking though, we will fail to reject the null hypothesis. However, in this case, since the p-value is so close to 0.05, we could either reject the null hypothesis or fail to reject it depending on whether we would be willing to relax the confidence level a bit. 

**Part 3(d)**

As explained in the previous answer, we could either fail to reject the null hypothesis (if we strictly go by the 95% confidence level), or we could reject the null hpothesis (if we are willing to lower our confidence level a bit).

- If we fail to reject the null hypothesis, then we conclude that the mean depression scores across the five weeks are the same, and that there is no difference in the depression levels before and after the earthquake.

 - If we reject the null hypothesis, then we conclude that atleast one pair of weeks among the possible ten pairs have unequal means
 
**Part 4**

Assumptions in ANOVA:

- The population from which our samples are drawn should be normally distributed. 
Drawing a q-q plot:

```{r, echo=TRUE, message=FALSE, warning=FALSE}
# calling the car library
library(car)

# drawing the q-q plot
qqPlot(scores, envelope = FALSE, 
       main = "Quantile-Comparison plot for depression scores ", 
       xlab = "Theoretical quantiles for a normal distribution", 
       ylab = "Depression scores")
```

Observing the plot above, we can say that the population of depression scores is approximately normal, and thus our assumption holds.

- The observations should be independent of each other

The data collected in this situation was collected in different weeks and thus the data points are not dependent on each other. Hence this assumption also holds.

- The variance between groups should be equal

Drawing a Residuals v/s Fitted plot:

```{r, echo=TRUE, message=FALSE, warning=FALSE}
plot(anova_model$fitted.values, anova_model$residuals,
     main = "Residual values v/s Fitted values",
     xlab = "Fitted values", ylab = "Residual values")
```

Observing the above plot, it can be concluded that the residuals are scattered around zero for all values of week to a similar degree. Hence there is constant variance between the groups (i.e., weeks). Hence this conclusion also holds.

**Part 5**

Pairwise confidence intervals using the Tuckey's pairwise comparison

```{r, echo=TRUE, message=FALSE, warning=FALSE}
# calling the R stats library
library(stats)

# carrying out Tukey's pairwise comparison
pair_comp = TukeyHSD(anova_model, which = 'week', conf.level = 0.95)
pair_comp
```

Based on this output, we can say that none of the pairwise comparisons show that the difference of means is statistically significant, except for the case of **Week 10 and Week -2**, where the p-value is **0.051**. We could say that the depression scores for Week 10 and Week -2 are unequal, but strictly speaking, even this difference is not statistically significant at 95% confidence level.

## Question 3

Reading the data and saving the columns of interest as **total** and **qb**

```{r, echo=TRUE, message=FALSE, warning=FALSE}
data = read.table("MS Analytics/6414/R Lecture Notes/Simple Linear Regression/qbsalary.txt", header=TRUE)
total = data$TOTAL
qb = data$QB
```

**Part 1**

Excluding the data points corresponding to Steelers and Bears and storing them in new variables

```{r, echo=TRUE, message=FALSE, warning=FALSE}
total.no.out = total[-c(12,16)]
qb.no.out = qb[-c(12,16)]
```

Scatterplots showing the relationship between the Total Salary and Regular Quarterback salary for the two cases can be drawn as follows. Also fitting a straight line through the points to get a sense of the direction.

```{r, echo=TRUE, message=FALSE, warning=FALSE}
par(mfrow=c(1,2))

plot(total, qb, 
     main = "Including Steelers and Bears", 
     xlab = "Total Salary of the team",
     ylab = "Salary of the regular quaterback",
     xlim = c(17000, 31000), ylim = c(400, 3500))
abline(lm(qb ~ total), col = "red")

plot(total.no.out, qb.no.out, 
     main = "Excluding Steelers and Bears", 
     xlab = "Total Salary of the team",
     ylab = "Salary of the regular quaterback",
     xlim = c(17000, 31000), ylim = c(400, 3500))
abline(lm(qb.no.out ~ total.no.out), col = "red")
```

From the above two scatterplots, it can be said that:

- In both the cases, the salary of the regular quarterback increases with the total salary of the team. In the case where Steelers and Bears are included, the slope of the line is greater, meaning that it is more positively related than the case in which Steelers and Bears are excluded

 - In both the cases, the form of the relationship can be loosely said to be linear, although this relationship is stronger in the case in which Steelers and Bears are included
 
**Part 2**

Fitting linear regression models for the two cases

```{r, echo=TRUE, message=FALSE, warning=FALSE}
# Model A: when the influential observations are included
modelA = lm(qb ~ total)
summary(modelA)
```

```{r, echo=TRUE, message=FALSE, warning=FALSE}
# Model B: when the influential observations are excluded
modelB = lm(qb.no.out ~ total.no.out)
summary(modelB)
```

**Part (i)**

The model parameters are:

- $\beta_{0}$ : Intercept; Quarterback salary when the total salary of the team is 0

- $\beta_{1}$ : Slope; The change in Quarterback salary associated with unit change in the total salary of the team

- $\sigma$ : Nuisance parameter; the standard error associated with the residuals of the model

Their estimates are as follows:

$\hat{\beta_{0, with-influential-obs}}$ = **-1650**

$\hat{\beta_{1, with-influential-obs}}$ = **0.136**

$\hat{\sigma_{with-influential-obs}}$ = **575.8**

$\hat{\beta_{0, w/o-influential-obs}}$ = **-580.75**

$\hat{\beta_{1, w/o-influential-obs}}$ = **0.084**

$\hat{\sigma_{w/o-influential-obs}}$ = **435**

**Part (ii)**

Equation of least squares line for the case in which influential observations have been included

$\hat{Quarterback.Salary}$ = $-1650 + 0.136 * Total.Team.Salary$

Equation of least squares line for the case in which influential observations have been excluded

$\hat{Quarterback.Salary}$ = $-580.75 + 0.084 * Total.Team.Salary$

**Part (iii)**

- *For the case in which influential observations have been included*: Here, $\beta_{1}$ is **0.136** which means that for a unit increase in the total team salary, there is an expected increase of 0.136 units in the Quarterback salary. Also, the standard error for this estimate is **0.037** which is a measure of the accuracy of predictions. It's value is fairly small, which means that we can be fairly certain about the predictions made by the regression line.

- *For the case in which influential observations have been excluded*: Here, $\beta_{1}$ is **0.084** which means that for a unit increase in the total team salary, there is an expected increase of 0.084 units in the Quarterback salary. Also, the standard error for this estimate is **0.033** which is a measure of the accuracy of predictions. It's value is fairly small, which means that we can be fairly certain about the predictions made by the regression line.

**Part (iv)**

The 99% confidence interval can be found for $\beta_{1}$ as follows:

$[l,u]$ $=$ $[\hat{\beta_{1}}$ $-$ $t_{0.005, n-1}$ * $se(\hat{\beta_{1}})$  $,$  $\hat{\beta_{1}}$ $+$ $t_{0.005, n-1}$ * $se(\hat{\beta_{1}})]$

- *For the case in which influential observations have been included*:
```{r, echo=TRUE, message=FALSE, warning=FALSE}
modelA$coef[2] + c(-1,1)*qt(.995, modelA$df)*0.03739
```

Hence, $[l,u]$ $=$ $[0.0324,0.2402]$

- *For the case in which influential observations have been excluded*:
```{r, echo=TRUE, message=FALSE, warning=FALSE}
modelB$coef[2] + c(-1,1)*qt(.995, modelB$df)*0.03261
```

Hence, $[l,u]$ $=$ $[-0.0071,0.1753]$

Yes, the two confidence intervals overlap in the range $[0.0324,0.1753]$

**Part 3**

Testing the significance of the linear relationship observed in the data

**Part (i)**

- *For the case in which influential observations have been included*: P-value is **0.001166**

- *For the case in which influential observations have been excluded*: P-value is **0.01653**

**Part (ii)**

The P-value is the smallest level of significance at which we can reject the null hypothesis $H_{0}$. Usually, the confidence level is taken to be 95%, which means that for P-values that are less than 0.05, the null hypothesis $H_{0}$ would be rejected.

**Part (iii)**

In both cases, the P-value is small (0.001166 and 0.01653 respectively), and hence we can reject the null hypothesis $H_{0}$ in both the cases. Hence, we accept the alternate hypothesis, meaning that there is a statistically significant relationship between the Quarterback salary and the Total Salary of the team

**Question 4**

The general equation to predict the salary of Quarterback given the total salary of the team is:

$\hat{Quarterback.Salary}$ = $\hat{\beta_{0}}$ $+$ $\hat{\beta_{0}}$ * $Total.Team.Salary$

Calculation in R:

- *For the case in which influential observations have been included*:

```{r, echo=TRUE, message=FALSE, warning=FALSE}
dataA = data.frame(total = 25000)
predict(modelA, dataA, interval = "prediction", level = 0.95, type = "response")
```

Hence, the predicted value of the salary of Quarterback when the Total Salary of the Team is 25,000,000 is **1,759,448**. For a 95% confidence level, the lower and upper values for the Quarterback salary are **(540,957.6, 2,977,937)**

- *For the case in which influential observations have been excluded*:

```{r, echo=TRUE, message=FALSE, warning=FALSE}
dataB = data.frame(total.no.out = 25000)
predict(modelB, dataB, interval = "prediction", level = 0.95, type = "response")
```

Hence, the predicted value of the salary of Quarterback when the Total Salary of the Team is 25,000,000 is **1,520,573**. For a 95% confidence level, the lower and upper values for the Quarterback salary are **(587,767.2, 2,453,378)**